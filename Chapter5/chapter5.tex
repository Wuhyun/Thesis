%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Fifth Chapter **********************************
%*******************************************************************************
\chapter{High-Resolution CMB Bispectrum Estimator}

% **************************** Define Graphics Path **************************
\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi

Intro: current methods for CMB bispectrum estimation.

\section{Formalism}
\subsection{Modal estimator?}
Review of the Modal estimator formalism

\subsection{CMB-BEst formalism}
Recall that the CMB bispectrum estimator for a given template can be written as
\begin{align}
	\hat{f}_{NL} = \frac{1}{N} \sum_{l_j,m_j} \frac{\mathcal{G}^{l_1 l_2 l_3}_{m_1 m_2 m_3} b_{l_1 l_2 l_3}}{C_{l_1} C_{l_2} C_{l_3}} \left[ a_{l_1 m_1} a_{l_2 m_2} a_{l_3 m_3} - \left( \left< a^G_{l_1 m_1} a^G_{l_2 m_2} \right> a_{l_3 m_3} + \text{2\ cyc.} \right)  \right].		\label{eqn:bispectrum_estimator_standard}
\end{align}
Here we omit superscripts $X$ for temperature and polarisation for notational convenience. Even though the formalism in this section will be presented for CMB temperature data only, the method is general and can easily be extended to include polarisation. For estimation of the full covariance matrix $C_{lm,l'm'}$ needed for the linear term, we use ensemble average from Gaussian simulations, as denoted by superscripts $G$ and the bracket $\left<\cdot\right>$.

The normalisation factor is given by
\begin{align}
	N = \sum_{l_j} \frac{h_{l_1 l_2 l_3}^2 b_{l_1 l_2 l_3}^2}{C_{l_1} C_{l_2} C_{l_3}}.
\end{align}

The core part of our estimation routine is the separable mode expansion of shape function;
\begin{align}
	S(k_1, k_2, k_3) := (k_1 k_2 k_3)^2 B(k_1, k_2, k_3) = \sum_{p_j} \alpha_{p_1 p_2 p_3} q_{p_1}(k_1) q_{p_2}(k_2) q_{p_3}(k_3).
\end{align}
Choices for the basis functions $q_p(k)$ are detailed in the next section. Due to the separability, the reduced bispectrum reduces to a compact form of
\begin{align}
	b_{l_1 l_2 l_3} = \sum_{p_j} \alpha_{p_1 p_2 p_3} \int dr \tilde{q}_{p_1}(l_1,r) \tilde{q}_{p_2}(l_2,r) \tilde{q}_{p_3}(l_3,r),
\end{align}
where the \textit{projected} mode functions are defined as
\begin{align}
	\tilde{q}_{p}(l,r) := \frac{2r^\frac{2}{3}}{\pi} \int dk q_p(k) \Delta_l(k) j_l (kr).
\end{align}
Radiative transfer functions $\Delta_l(k)$ and spherical Bessel functions $j_l(kr)$ are denoted the same way as the previous chapter.

Every term appearing in (\ref{eqn:bispectrum_estimator_standard}) except the Gaunt integral is now separable. Using the definition $\mathcal{G}^{l_1 l_2 l_3}_{m_1 m_2 m_3} = \int d^2 \vv{n} Y_{l_1 m_1}(\vv{n}) Y_{l_2 m_2}(\vv{n}) Y_{l_3 m_3}(\vv{n})$, we can render it separable at the cost of introducing an extra integral.

Define the filtered maps as
\begin{align}
	M^{(i)}_p (\vv{n}, r) := \sum_{l,m} \frac{\tilde{q}_p (l,r)}{C_l} a^{(i)}_{lm} Y_{lm} (\vv{n}),
\end{align}
where $a^{(i)}_{lm}$'s are represent the spherical harmonic transform of the $i$th CMB map. The convention is so that $0$th map corresponds to the observed CMB map, while maps number $1$-$N_{sims}$ are Gaussian simulations. Without the factors involving $\tilde{q}$ and $C_l$'s, $M$ is simply equal to the original map in real space. Each mode extracts different anisotropy scales present in the map.

The bispectrum estimator (\ref{eqn:bispectrum_estimator_standard}) reduces to
\begin{align}
	\hat{f}_{NL} = \frac{1}{N} \sum_{p_j} \alpha_{p_1 p_2 p_3} (\beta^{cub}_{p_1 p_2 p_3} - 3 \beta^{lin}_{p_1 p_2 p_3}),
\end{align}
where most of the computation required is now contained in the `$\beta$'s, given by
\begin{align}
	\beta^{cub}_{p_1 p_2 p_3} &:= \int dr \int d^2\vv{n} \; M^{(0)}_{p_1} (\vv{n},r) M^{(0)}_{p_2} (\vv{n},r) M^{(0)}_{p_3} (\vv{n},r),	\label{def:beta_cubic} \\
	\beta^{lin}_{p_1 p_2 p_3} &:= \frac{1}{N_{sims}} \sum_{j=1}^{N_{sim}} \int dr \int d^2\vv{n} \; M^{(j)}_{p_1} (\vv{n},r) M^{(j)}_{p_2} (\vv{n},r) M^{(0)}_{p_3} (\vv{n},r). \label{def:beta_linear}
\end{align}
It is important to note that the beta matrices depends only on the choice of mode functions and input map data, and are independent of the theoretical bispectrum considered. Once $\beta^{cub}$ and $\beta^{lin}$ are computed and stored, we may constrain any model of interest by decomposing the template to get $\alpha$, and then simply taking a dot product: $\vv{\alpha} \cdot \vv{\beta} / N$.

The normalisation can also be obtained in a similar fashion;
\begin{align}
	N = \sum_{p_j, p'_j} \alpha_{p_1 p_2 p_3} \Gamma_{p_1 p_2 p_3, p'_1, p'_2, p'_3} \alpha_{p'_1, p'_2, p'_3},
\end{align}
or equivalently, $N = \vv{\alpha}^T \Gamma \vv{\alpha}$. We exploit separability once again to compute the $\Gamma$ matrix;
\begin{align}
	\Gamma_{p_1 p_2 p_3, p'_1, p'_2, p'_3} &:= \int dr \int d\mu \mathcal{P}_{p_1 p'_1}(\mu, r, r') \mathcal{P}_{p_3 p'_3}(\mu, r, r') \mathcal{P}_{p_3 p'_3}(\mu, r, r'), 	\label{def:gamma} 	\\
	\mathcal{P}_{p p'}(\mu, r, r') &:= \sum_l \frac{2l+1}{(8\pi)^{1/3} C_l} \tilde{q}_p'(l,r) \tilde{q}_p(l,r') P_l(\mu),
\end{align}
where $P_l(\mu)$'s are the Legendre polynomials.

In summary, CMB-BEst computes the main quantities: $\beta^{cub}$, $\beta^{lin}$, and $\Gamma$. The most computationally expensive part is the linear term $\beta^{lin}$ by a couple orders of magnitude in most cases. Considerable effort has been put to optimise corresponding part of the code, which will be detailed in the following sections.

\subsection{Basis functions}

Special case (pmax=2) -> ones used in forecast for constant feature models.
KSW choice (pmax=4)
Legendre functions basis. Augmentation - 1/k basis.

Decomposition. Separability -> three separate integrations

\section{Implementation and optimisation}

The CMB-BEst formalism significantly reduces the amount of computation needed for the CMB bispectrum estimation. Obtaining the linear term $\beta^{lin}$ in (\ref{def:beta_linear}), however, is still practically impossible unless thoroughly optimised. In this section, we provide details for various aspects of our optimisation process: algorithm design, parallel computing, and data locality improvements. Final specifications and data files used are outlined at the end.

\subsection{Algorithm}
Basic order of integration, psuedo-codes, justifications
Data used, programs used, etc.

% I want to remove 'end for's - figure out later!

\begin{algorithm}[htbp]
	\caption{Computing $\beta$s: the na\"ive method}
	\label{alg:beta_first_attempt}
	\begin{algorithmic}[1] % The number tells where the line numbering should start	
		\State Allocate $M(i,p,n)$
		\Comment{Memory $\sim O(N_{sims} \cdot p_{max} \cdot N_{pix})$}

		\\
		\For{each map $i$}
			\For{each mode $p$}
			\Comment{$O(N_{sims} \cdot p_{max} \cdot N_{pix}^{3/2})$}
				\State \textbf{compute} $M(i,p,n)$ by SHT
			\EndFor
		\EndFor \Comment{$M(i,p,n)$ ready}
		\\
		
		\For{each map $i$}
			\For{each set of modes $(p_1,p_2,p_3)$}
				\For{each pixel $n$}
				\Comment{$O(N_{sims} \cdot p_{max}^3 \cdot N_{pix})$}
					\State $\beta^{cub}(i, p_1, p_2, p_3) \pluseq M(i,p_1,n) \cdot M(i,p_2,n) \cdot M(i,p_3,n)$
				\EndFor
			\EndFor
		\EndFor

		\\	
		\For{each map $i$}
			\For{each map $j \neq i$}
				\For{each set of modes $(p_1,p_2,p_3)$}
					\For{each pixel $n$}
					\Comment{$O(N_{sims}^2 \cdot p_{max}^3 \cdot N_{pix})$}
						\State $\beta^{lin}(i, p_1, p_2, p_3) \pluseq M(j,p_1,n) \cdot M(j,p_2,n) \cdot M(i,p_3,n)$
					\EndFor
				\EndFor
			\EndFor
		\EndFor

	\end{algorithmic}
\end{algorithm}

(Afterwards, subtract beta cubic from beta linear and divide it by Nsims-1) 

\begin{algorithm}[htbp]
	\caption{Computing $\beta$s: optimised for computation}
	\label{alg:beta_second_attempt}
	\begin{algorithmic}[1] % The number tells where the line numbering should start	
		\State Allocate $M(i,p,n)$ \Comment{$O(N_{sims} \cdot p_{max} \cdot N_{pix})$}
		\State Allocate $C(p_1,p_2,n)$ \Comment{$O(p_{max} \cdot p_{max} \cdot N_{pix})$}
		\\
		\For{each map $i$}
			\For{each mode $p$}
				\Comment{$O(N_{sims} \cdot p_{max} \cdot N_{pix}^{3/2})$}
				\State \textbf{compute} $M(i,p,n)$ by SHT
			\EndFor
		\EndFor \Comment{$M(i,p,n)$ ready}
		\\
		\For{each map $j$}
			\For{each pair of modes $(p_1,p_2)$}
				\For{each pixel $n$}
					\Comment{$O(N_{sims} \cdot p_{max}^2 \cdot N_{pix})$}
					\State $C(p_1,p_2,n) \pluseq M(j,p_1,n) \cdot M(j,p_2,n)$
				\EndFor
			\EndFor
		\EndFor \Comment{$C(p_1,p_2,n)$ ready}
		\\
		\For{each map $i$}
			\For{each set of modes $(p_1,p_2,p_3)$}
				\For{each pixel $n$}
					\Comment{$O(N_{sims} \cdot p_{max}^3 \cdot N_{pix})$}
					\State $\beta^{cub}(i, p_1, p_2, p_3) \pluseq M(i, p_1, n) \cdot M(i, p_2, n) \cdot M(i, p_3, n)$
					\State $\beta^{lin}(i, p_1, p_2, p_3) \pluseq C(p_1, p_2, n) \cdot M(i, p_3, n)$
				\EndFor
			\EndFor
		\EndFor
	\end{algorithmic}
\end{algorithm}


\begin{algorithm}[htbp]
	\caption{Computing $\beta$s: fast and memory efficient}
	\label{alg:beta_third_attempt}
	\begin{algorithmic}[1] % The number tells where the line numbering should start	
		\State Allocate $m(p,n)$ \Comment{$O(p_{max} \cdot N_{pix})$}
		\State Allocate $C(p_1,p_2,n)$ \Comment{$O(p_{max} \cdot p_{max} \cdot N_{pix})$}
		\\
		\For{each map $i$}
			\For{each mode $p$}
				\Comment{$O(N_{sims} \cdot p_{max} \cdot N_{pix}^{3/2})$}
				\State \textbf{compute} $M(i,p,n)$ by SHT and store in $m(p,n)$
			\EndFor
			\\
			\For{each pair of modes $(p_1,p_2)$}
				\Comment{$O(N_{sims} \cdot p_{max}^2 \cdot N_{pix})$}
				\For{each pixel $n$}
					\State $C(p_1,p_2,n) \pluseq m(p_1,n) \cdot m(p_2,n)$
				\EndFor
			\EndFor
		\EndFor
		\Comment{$C(p_1,p_2,n)$ ready}
		\\
		\For{each map $i$}
			\For{each of mode $p$}
				\Comment{$O(N_{sims} \cdot p_{max} \cdot N_{pix}^{3/2})$}
				\State \textbf{compute} $M(i,p,n)$ by SHT and store in $m(p,n)$
			\EndFor
			\\
			\For{each set of modes $(p_1,p_2,p_3)$}			
				\For{each pixel $n$}
					\Comment{$O(N_{sims} \cdot p_{max}^3 \cdot N_{pix})$}	
					\State $\beta^{cub}(i, p_1, p_2, p_3) \pluseq m(p_1,n) \cdot m(p_2,n) \cdot m(p_3,n)$
					\State $\beta^{lin}(i, p_1, p_2, p_3) \pluseq C(p_1, p_2, n) \cdot m( p_3, n)$
				\EndFor
			\EndFor
		\EndFor
	\end{algorithmic}
\end{algorithm}

\subsection{Parallel computing}
Table: 3 levels of parallelisation. How CMB-BEst exploits each level.

\subsection{Data locality}
Cache blocking. Some Amplxe results screenshot to confirm?
+ Initialising parts of large arrays at processors that actually use them.

\subsection{Cluster adaptation}
Three different versions of the code. Balance between performance / memory.

\subsection{Final specifications}
Code, runtime, etc? 

\section{Verification}
\subsection{Internal consistency checks}
Quick derivation of optimality of the bispectrum estimator?
Sample versus Theory covariance checks.
Expected chi-square distribution etc.

\subsection{Consistency with Planck}

Consistency vs Modal for Planck results.
Discussion on kmin and kmax range
